{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/')\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "max_prop = 1000\n",
    "coaxialeff = 450000/(max_prop**2)\n",
    "coefthrust = 5.7199 / (max_prop**2)\n",
    "coeftorque = 0.4008 / (max_prop**2)\n",
    "k = coefthrust\n",
    "b = coeftorque\n",
    "Lx = 0.36 / 2\n",
    "Ly = 0.26 / 2 \n",
    "Lz = 0.0221\n",
    "\n",
    "BATCH = 256\n",
    "\n",
    "alpha = torch.randn(size=[BATCH, 1]).cuda()\n",
    "d = torch.randn(size=[BATCH, 1]).cuda()\n",
    "controlmatrix = np.zeros([BATCH, 4, 8])\n",
    "d_scale = 0.43/2.0\n",
    "dcg = d * d_scale + d_scale\n",
    "c = torch.cos(alpha*torch.pi/2.0)\n",
    "s = torch.sin(alpha*torch.pi/2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6795],\n",
       "        [ 0.5437],\n",
       "        [ 0.7230],\n",
       "        [ 0.9860],\n",
       "        [ 0.3331],\n",
       "        [ 0.6422],\n",
       "        [ 0.9298],\n",
       "        [-0.2829],\n",
       "        [ 0.4912],\n",
       "        [ 0.6392],\n",
       "        [ 0.7430],\n",
       "        [ 0.9822],\n",
       "        [ 0.7229],\n",
       "        [ 0.9226],\n",
       "        [ 0.3674],\n",
       "        [-0.3948],\n",
       "        [ 0.8354],\n",
       "        [ 1.0000],\n",
       "        [-0.6449],\n",
       "        [ 0.4644],\n",
       "        [ 0.9789],\n",
       "        [ 0.1249],\n",
       "        [ 0.0642],\n",
       "        [ 0.8616],\n",
       "        [ 0.7673],\n",
       "        [-0.9410],\n",
       "        [-0.3949],\n",
       "        [ 0.4526],\n",
       "        [ 0.8878],\n",
       "        [-0.4240],\n",
       "        [ 0.8504],\n",
       "        [ 0.1057],\n",
       "        [ 0.9974],\n",
       "        [-0.5917],\n",
       "        [-0.6508],\n",
       "        [ 0.5900],\n",
       "        [ 0.2424],\n",
       "        [ 0.5310],\n",
       "        [-0.4113],\n",
       "        [ 0.9963],\n",
       "        [ 0.9784],\n",
       "        [ 0.7600],\n",
       "        [ 0.5439],\n",
       "        [-0.9870],\n",
       "        [ 0.9509],\n",
       "        [ 0.9583],\n",
       "        [-0.5072],\n",
       "        [-0.7406],\n",
       "        [ 0.0957],\n",
       "        [ 0.7396],\n",
       "        [-0.4920],\n",
       "        [ 0.2898],\n",
       "        [ 0.0204],\n",
       "        [ 0.0114],\n",
       "        [ 0.8307],\n",
       "        [ 0.1289],\n",
       "        [ 0.3054],\n",
       "        [-0.2849],\n",
       "        [ 0.4345],\n",
       "        [ 0.9218],\n",
       "        [ 0.9568],\n",
       "        [ 0.1155],\n",
       "        [ 0.0562],\n",
       "        [ 0.6230],\n",
       "        [ 0.2468],\n",
       "        [ 0.9791],\n",
       "        [ 0.3597],\n",
       "        [ 0.9634],\n",
       "        [-0.4610],\n",
       "        [ 0.3024],\n",
       "        [ 0.9748],\n",
       "        [ 0.5708],\n",
       "        [ 0.8493],\n",
       "        [ 0.1385],\n",
       "        [-0.7149],\n",
       "        [ 0.2467],\n",
       "        [-0.1343],\n",
       "        [ 0.4778],\n",
       "        [ 0.9113],\n",
       "        [-0.7553],\n",
       "        [-0.4743],\n",
       "        [-0.4105],\n",
       "        [ 0.7263],\n",
       "        [ 0.3597],\n",
       "        [-0.1315],\n",
       "        [ 0.8846],\n",
       "        [-0.0418],\n",
       "        [ 0.0417],\n",
       "        [-0.9452],\n",
       "        [ 0.9586],\n",
       "        [ 0.7494],\n",
       "        [ 0.8283],\n",
       "        [-0.2150],\n",
       "        [ 0.2174],\n",
       "        [ 0.0921],\n",
       "        [ 0.9953],\n",
       "        [ 0.8557],\n",
       "        [-0.3335],\n",
       "        [ 0.9626],\n",
       "        [ 0.2664],\n",
       "        [ 0.7516],\n",
       "        [ 0.3387],\n",
       "        [ 0.9931],\n",
       "        [ 0.9935],\n",
       "        [ 0.6539],\n",
       "        [ 0.6336],\n",
       "        [ 0.4209],\n",
       "        [ 0.9875],\n",
       "        [ 1.0000],\n",
       "        [ 0.1902],\n",
       "        [-0.9309],\n",
       "        [-0.8081],\n",
       "        [-0.0906],\n",
       "        [ 0.4482],\n",
       "        [ 0.5771],\n",
       "        [ 0.9900],\n",
       "        [ 0.9120],\n",
       "        [ 0.9365],\n",
       "        [ 0.5873],\n",
       "        [-0.5737],\n",
       "        [ 0.9706],\n",
       "        [ 0.9509],\n",
       "        [ 0.9434],\n",
       "        [ 0.9717],\n",
       "        [ 0.4283],\n",
       "        [ 0.0876],\n",
       "        [ 0.9731],\n",
       "        [ 0.7771],\n",
       "        [ 0.9777],\n",
       "        [ 0.2984],\n",
       "        [-0.1898],\n",
       "        [-0.6717],\n",
       "        [ 0.6394],\n",
       "        [ 0.9443],\n",
       "        [ 0.0201],\n",
       "        [ 0.9182],\n",
       "        [-0.3098],\n",
       "        [-0.0010],\n",
       "        [ 0.9547],\n",
       "        [-0.8427],\n",
       "        [ 0.9741],\n",
       "        [ 0.8068],\n",
       "        [ 0.9988],\n",
       "        [-0.0603],\n",
       "        [ 0.8641],\n",
       "        [ 0.5751],\n",
       "        [ 0.8605],\n",
       "        [ 0.0185],\n",
       "        [ 0.2199],\n",
       "        [ 0.9995],\n",
       "        [ 0.9901],\n",
       "        [ 0.7210],\n",
       "        [-0.8207],\n",
       "        [ 0.7660],\n",
       "        [-0.5196],\n",
       "        [-0.9412],\n",
       "        [ 0.6092],\n",
       "        [ 0.9922],\n",
       "        [ 0.6710],\n",
       "        [-0.9446],\n",
       "        [-0.2030],\n",
       "        [-0.6566],\n",
       "        [-0.2330],\n",
       "        [ 0.4686],\n",
       "        [ 0.2126],\n",
       "        [ 0.0752],\n",
       "        [ 0.2365],\n",
       "        [-0.1835],\n",
       "        [ 0.3262],\n",
       "        [-0.9850],\n",
       "        [ 0.7755],\n",
       "        [-0.1496],\n",
       "        [ 0.9999],\n",
       "        [ 0.7655],\n",
       "        [-0.9147],\n",
       "        [ 0.6459],\n",
       "        [ 0.9795],\n",
       "        [ 0.4319],\n",
       "        [-0.2801],\n",
       "        [ 0.6790],\n",
       "        [ 0.7996],\n",
       "        [ 0.1686],\n",
       "        [ 0.9322],\n",
       "        [ 0.6088],\n",
       "        [ 0.8946],\n",
       "        [ 0.9283],\n",
       "        [-0.9306],\n",
       "        [ 0.9103],\n",
       "        [ 0.0578],\n",
       "        [ 0.6603],\n",
       "        [ 0.9761],\n",
       "        [ 0.4806],\n",
       "        [ 0.9844],\n",
       "        [-0.9032],\n",
       "        [ 0.6723],\n",
       "        [-0.0250],\n",
       "        [-0.0230],\n",
       "        [-0.9494],\n",
       "        [-0.9899],\n",
       "        [ 0.8031],\n",
       "        [ 0.4330],\n",
       "        [-0.9988],\n",
       "        [ 0.8413],\n",
       "        [ 0.7358],\n",
       "        [ 0.8858],\n",
       "        [ 0.9999],\n",
       "        [ 0.4653],\n",
       "        [ 0.2310],\n",
       "        [ 0.9689],\n",
       "        [ 0.9508],\n",
       "        [-0.2324],\n",
       "        [ 0.7114],\n",
       "        [ 0.3719],\n",
       "        [ 0.9681],\n",
       "        [-0.5625],\n",
       "        [ 0.8880],\n",
       "        [ 0.9721],\n",
       "        [-0.2951],\n",
       "        [-0.7931],\n",
       "        [-0.8685],\n",
       "        [-0.9988],\n",
       "        [-0.9752],\n",
       "        [-0.9817],\n",
       "        [-0.8903],\n",
       "        [ 0.9486],\n",
       "        [ 0.9975],\n",
       "        [ 0.9968],\n",
       "        [-0.2500],\n",
       "        [ 0.9256],\n",
       "        [ 0.0146],\n",
       "        [ 0.6659],\n",
       "        [ 0.9871],\n",
       "        [ 0.9961],\n",
       "        [ 0.9936],\n",
       "        [ 0.9180],\n",
       "        [ 0.5711],\n",
       "        [ 0.7551],\n",
       "        [ 0.0608],\n",
       "        [ 0.9929],\n",
       "        [-0.0025],\n",
       "        [ 0.4970],\n",
       "        [-0.5666],\n",
       "        [ 0.7898],\n",
       "        [ 0.9994],\n",
       "        [-0.9981],\n",
       "        [-0.2421],\n",
       "        [ 0.0047],\n",
       "        [ 0.2093],\n",
       "        [ 0.1618],\n",
       "        [-0.0558],\n",
       "        [ 0.6008],\n",
       "        [ 0.9985],\n",
       "        [ 0.9863],\n",
       "        [ 0.7115],\n",
       "        [ 0.9271],\n",
       "        [-0.9561]], device='cuda:0')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixfront = torch.Tensor([[Lx*k, Lx*k, -Lx*k, -Lx*k], \n",
    "                         [-Ly*k, -Ly*k, -Ly*k, -Ly*k], \n",
    "                         [b, -b, -b, b], \n",
    "                         [k, k, k, k]]).type(torch.float32).cuda()\n",
    "matrixfront = matrixfront.unsqueeze(dim=0).expand(BATCH, 4, 4)\n",
    "d_bias = torch.Tensor([[0,0,0,0], \n",
    "                         [1,1,1,1], \n",
    "                         [0,0,0,0], \n",
    "                         [0,0,0,0]]).type(torch.float32).cuda()\n",
    "d_bias = d_bias.unsqueeze(dim=0).expand(BATCH, 4, 4)\n",
    "d_bias = d_bias * dcg.unsqueeze(dim=1).expand(BATCH, 4, 4)\n",
    "matrixfront = matrixfront + d_bias * k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2346], device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dcg[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.2346, -0.2346, -0.2346, -0.2346],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.0000],\n",
       "        [-0.0000, -0.0000, -0.0000, -0.0000]], device='cuda:0')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_bias[0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrixback = torch.Tensor([[-Lx*k, -Lx*k, Lx*k, Lx*k], \n",
    "                         [Ly*k, Ly*k, Ly*k, Ly*k], \n",
    "                         [b, -b, -b, b], \n",
    "                         [k, k, k, k]]).type(torch.float32).cuda()\n",
    "matrixback = matrixback.unsqueeze(dim=0).expand(BATCH, 4, 4)\n",
    "matrixback = matrixback * c.unsqueeze(dim=1).expand(BATCH, 4, 4)\n",
    "\n",
    "d_bias = torch.Tensor([[0,0,0,0], \n",
    "                         [1,1,1,1], \n",
    "                         [0,0,0,0], \n",
    "                         [0,0,0,0]]).type(torch.float32).cuda()\n",
    "d_bias = d_bias.unsqueeze(dim=0).expand(BATCH, 4, 4)\n",
    "d_bias = d_bias * dcg.unsqueeze(dim=1).expand(BATCH, 4, 4)\n",
    "matrixback = matrixback + d_bias * k * c.unsqueeze(dim=1).expand(BATCH, 4, 4)\n",
    "\n",
    "bias_roll = torch.Tensor([[-1,-1,-1,-1], \n",
    "                         [0,0,0,0], \n",
    "                         [0,0,0,0], \n",
    "                         [0,0,0,0]]).type(torch.float32).cuda()\n",
    "bias_roll = bias_roll.unsqueeze(dim=0).expand(BATCH, 4, 4)\n",
    "bias_roll = bias_roll * s.unsqueeze(dim=1).expand(BATCH, 4, 4) * b\n",
    "matrixback = matrixback + bias_roll\n",
    "\n",
    "bias_z = torch.Tensor([[0,0,0,0], \n",
    "                    [-1,-1,-1,-1], \n",
    "                    [0,0,0,0], \n",
    "                    [0,0,0,0]]).type(torch.float32).cuda()\n",
    "bias_z = bias_z.unsqueeze(dim=0).expand(BATCH, 4, 4)\n",
    "bias_z = bias_z * s.unsqueeze(dim=1).expand(BATCH, 4, 4) * Lz * k\n",
    "matrixback = matrixback + bias_z\n",
    "\n",
    "controlmatrix = torch.concat([matrixfront, matrixback], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 4, 8])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "controlmatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 ** 15"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
